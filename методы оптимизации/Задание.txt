1. Реализуйте алгоритм (а) градиентного спуска и (б) стохастического градиентного спуска для решения задачи нахождения минимума (максимума) для выбранной дифференцируемой функции двух переменных.
2. Визуализируйте на графике схождение алгоритмов (а) и (б) к точке экстремума, воспользовавшись, например, функцией contour_plot() из ноутбука "Optimization_methods.ipynb".
3. С помощью фреймворка keras реализуйте полносвязую нейронную сеть с одним скрытым слоем для решения задачи классификации на датасете bioresponse.csv из Лабораторной работы №2, применив алгоритм оптимизации "Adam".